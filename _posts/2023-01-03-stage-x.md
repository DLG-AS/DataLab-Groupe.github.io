---
layout: post

title: Research Internship Prize for Information Extraction
subtitle: An internship in the DataLab Groupe recieved the research internship prize at Ecole Polytechnique
thumbnail-img: /assets/img/prix-stage-x.webp
cover-img: /assets/img/prix-stage-x.webp

tags: [internship, prize, information extraction]

comments: true

pinned: true
---

Information extraction from scanned documents is a difficult task which has
attracted increasing interest lately due to its usefulness in various document
processing use cases.

A robust extraction model should meet some criteria:

- Perform well on information extraction tasks
- Be fast
- Learn from little annotated data
- Generalise on new data layouts

The DataLab Groupe (ITD) developed thanks to its R&D a new generation of
information extraction models which meets the previous criteria and breaks free
from some limitations of current generations of information extraction models.

Those works on that new approach named "DocParser" will be shared to the
scientific community with the publication of a paper at the ICDAR 2023
conference.

As those works have been initiated and implemented during an internship inside
the DataLab Groupe, the research internship prize was attributed to that
internship during graduation day at the Ecole Polytechnique on december 9. The
contest included all the internships of the Data Science curriculum in the IT
department and the prize rewarded the innovation and the results acquired.


# Current information extraction approaches and their limitations

## Current approaches

Current approaches to information extraction often use a third party OCR with
visual information. OCR solutions allow to read all the words inside of the
document. Extraction follows two steps
- The document is OCRized
- Two approaches can then be used
    - The model detects where the information is based on visual data and the text acquired through OCR and then extracts the relevant fields
    - The model detects the fields to extract using the text acquired through OCR potentially using visual data

## Limitations of current approaches

Current OCR based approaches are limited
- They are always limited by the quality of the OCR. Global performance is impacted by a possibly slow and inaccurate OCR module
- Training requires visual and positional annotations (bounding boxes around the relevant fields) in addition to the textual values. That kind of annotation is costly.

# DocParser: a new generation of information extraction

With the goal of overcoming the previous limitations, the DataLab Groupe
developed an innovating end to end information extraction approach called
DocParser.

Contrary to previous approaches, DocParser does not require an OCR module
and only needs textual annotations for training. Furthermore, DocParser
improves extraction performance while being faster.

The model has an encoder-decoder architecture. The input is the image from
which we want to extract fields. The outputs are the values of the fields.

Here are the processing steps:
- The encoder encodes the image into a grid containing the most important visual info
- The decoder seraches for the position of the field based on the grid
- The decoder reads the value of the field and extracts character by character

# What does that mean to the Credit Agricole?

The DataLab Groupe ensures constant improvement of its AI extraction
information solution.

The goal is to deploy a well performing AI based information extraction
solution.

Through those works, the DataLab Groupe has come up with a new generation
of information extraction models which performs better and is freed from
previous limitations.

Thus, those works will be published in the ICDAR 2023 conference as our
new generation reaches the state of the art

